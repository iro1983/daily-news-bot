import os
import feedparser
import google.generativeai as genai
from datetime import datetime
import time

# ================= é…ç½®åŒº =================
api_key = os.environ.get("GOOGLE_API_KEY")

# ================= 1. åŠ¨æ€è·å–æ¨¡å‹ (ç»å¯¹é˜² 404) =================
def get_best_model():
    if not api_key: 
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° API Key")
        return None
    
    genai.configure(api_key=api_key)
    try:
        print("ğŸ” æ­£åœ¨æ‰«æä½ çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
        # è·å–æ‰€æœ‰æ”¯æŒæ–‡æœ¬ç”Ÿæˆçš„æ¨¡å‹å¯¹è±¡
        model_list = list(genai.list_models())
        
        # ç­›é€‰å‡ºæ”¯æŒ generateContent çš„æ¨¡å‹åç§°
        supported_models = [m.name for m in model_list if 'generateContent' in m.supported_generation_methods]
        
        if not supported_models:
            print("âŒ ä¸¥é‡é”™è¯¯ï¼šGoogle è¿”å›çš„æ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼")
            return None
            
        print(f"ğŸ“‹ ä½ çš„è´¦å·å¯ç”¨æ¨¡å‹: {supported_models}")

        # --- ä¼˜å…ˆçº§åŒ¹é…ç­–ç•¥ (åªç”¨åˆ—è¡¨é‡ŒçœŸå®å­˜åœ¨çš„åå­—) ---
        
        # ç­–ç•¥ 1: ä¼˜å…ˆæ‰¾ Flash ç³»åˆ— (é€Ÿåº¦å¿«ï¼Œæ”¯æŒé•¿æ–‡)
        # åªè¦åå­—é‡Œå¸¦ 'flash'ï¼Œä¸ç®¡å®ƒæ˜¯ 1.5 è¿˜æ˜¯ 2.5ï¼Œç›´æ¥ç”¨
        for name in supported_models:
            if 'flash' in name.lower():
                print(f"âœ… è‡ªåŠ¨é€‰ä¸­ Flash æ¨¡å‹: {name}")
                return genai.GenerativeModel(name)
        
        # ç­–ç•¥ 2: å¦‚æœæ²¡æœ‰ Flashï¼Œæ‰¾ Pro ç³»åˆ—
        for name in supported_models:
            if 'pro' in name.lower():
                print(f"âœ… è‡ªåŠ¨é€‰ä¸­ Pro æ¨¡å‹: {name}")
                return genai.GenerativeModel(name)
        
        # ç­–ç•¥ 3: å®åœ¨æ²¡æœ‰ï¼Œå°±ç”¨åˆ—è¡¨é‡Œçš„ç¬¬ä¸€ä¸ª (ç›²é€‰)
        first_model = supported_models[0]
        print(f"âš ï¸ æœªè¯†åˆ«å‡ºå¸¸ç”¨æ¨¡å‹ï¼Œå¼ºåˆ¶ä½¿ç”¨ç¬¬ä¸€ä¸ª: {first_model}")
        return genai.GenerativeModel(first_model)
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŒ¹é…å¤±è´¥: {e}")
        return None

# ================= 2. æ·±åº¦æ•°æ®é‡‡é›† (é«˜äº§ç‰ˆ) =================
def get_data():
    print("ğŸš€ å¼€å§‹å…¨ç½‘æƒ…æŠ¥æŒ–æ˜ (15+æ¡ç‰ˆ)...")
    data_text = ""
    
    # 1. Google Trends (æŠ“20æ¡)
    try:
        feed = feedparser.parse("https://trends.google.com/trends/trendingsearches/daily/rss?geo=US")
        data_text += "\nã€Google Trends (Macro)ã€‘:\n"
        for entry in feed.entries[:20]:
            traffic = getattr(entry, 'ht_approx_traffic', 'N/A')
            data_text += f"- Keyword: {entry.title} (Traffic: {traffic})\n  News: {entry.description}\n"
    except Exception as e:
        print(f"âš ï¸ Google è·³è¿‡: {e}")

    # 2. Reddit å‚ç›´æ¿å— (æ¯ä¸ªæŠ“8æ¡)
    reddit_feeds = [
        ("r/Entrepreneur", "https://www.reddit.com/r/Entrepreneur/top/.rss?t=day"), 
        ("r/SideProject", "https://www.reddit.com/r/SideProject/top/.rss?t=day"),   
        ("r/technology", "https://www.reddit.com/r/technology/top/.rss?t=day"),     
        ("r/popular", "https://www.reddit.com/r/popular/top/.rss?t=day"),           
        ("r/marketing", "https://www.reddit.com/r/marketing/top/.rss?t=day")        
    ]

    for source_name, url in reddit_feeds:
        try:
            print(f"ğŸ’ æ­£åœ¨æŒ–æ˜ {source_name}...")
            feed = feedparser.parse(url, agent="Mozilla/5.0")
            if feed.entries:
                data_text += f"\nã€Source: {source_name}ã€‘:\n"
                for entry in feed.entries[:8]: 
                    content_snippet = "No Content"
                    if hasattr(entry, 'content'):
                        content_snippet = entry.content[0].value[:600]
                    elif hasattr(entry, 'summary'):
                        content_snippet = entry.summary[:600]
                    content_snippet = content_snippet.replace("<p>", "").replace("</p>", "").replace("<br>", " ")
                    
                    data_text += f"--- Post ---\nTitle: {entry.title}\nLink: {entry.link}\nSnippet: {content_snippet}\n"
        except Exception as e:
            print(f"âš ï¸ {source_name} è·³è¿‡")
            
    return data_text

# ================= 3. AI åŒè¯­åˆ†æ (å¼ºåˆ¶æ•°é‡) =================
def analyze_to_html(text_data):
    model = get_best_model()
    if not model: return "<h1>AI é…ç½®å¤±è´¥ï¼šæœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹</h1>"

    date_str = datetime.now().strftime("%Y-%m-%d")
    print(f"ğŸ§  AI æ­£åœ¨è¿›è¡Œå¤§è§„æ¨¡åŒè¯­åˆ†æ...")
    
    prompt = f"""
    You are an expert "Business Intelligence Analyst". Today is {date_str}.
    I have provided extensive raw data from Google Trends and Reddit.

    ã€Goalã€‘
    Create a **Bilingual (English & Chinese)** Business Intelligence Report.
    Identify **Business Opportunities**, **User Pain Points**, and **Viral Trends**.

    ã€Quantity Requirementã€‘
    **CRITICAL**: You MUST generate at least **15 items** in total. 
    (Generate 5 items for EACH of the 3 sections below).

    ã€Output Structureã€‘
    Please generate 3 sections.

    ### Section 1: ğŸš€ Business Opportunities & Pain Points (å•†æœºä¸ç—›ç‚¹)
    *Target: 5 items* (Source: r/Entrepreneur, r/SideProject)
    * **Card Content**:
      - **Headline**: English Title / ä¸­æ–‡æ ‡é¢˜
      - **Analysis (Bilingual)**:
        - **EN**: Briefly analyze the pain point or opportunity.
        - **CN**: ç®€è¦åˆ†æç—›ç‚¹æˆ–å•†æœºã€‚
      - **Actionable Tip**: One specific advice (Bilingual).

    ### Section 2: ğŸ”¥ Viral Trends & Traffic (æµé‡å¯†ç )
    *Target: 5 items* (Source: Google Trends & r/popular)
    * **Card Content**:
      - **Headline**: English Keyword / ä¸­æ–‡çƒ­è¯
      - **Context (Bilingual)**:
        - **EN**: Why is this trending?
        - **CN**: ä¸ºä»€ä¹ˆç«äº†ï¼Ÿ
      - **Marketing Angle**: How to use this trend? (Bilingual).

    ### Section 3: ğŸ’¡ Tech & Industry Signals (è¡Œä¸šä¿¡å·)
    *Target: 5 items* (Source: r/technology, r/business)
    * **Card Content**:
      - **Headline**: English Event / ä¸­æ–‡äº‹ä»¶
      - **Impact (Bilingual)**:
        - **EN**: Why does it matter?
        - **CN**: ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ

    ã€Design & CSSã€‘
    - **Theme**: Dark Professional Mode (#1a1b1e background).
    - **Typography**: English (Light Gray #ced4da), Chinese (White #ffffff).
    - **Layout**: Grid cards (Responsive).
    - **Tags**: Show Source & Category tags clearly.

    ã€Raw Dataã€‘
    {text_data}
    
    Output ONLY valid HTML code.
    """

    try:
        response = model.generate_content(prompt)
        return response.text.replace("```html", "").replace("```", "")
    except Exception as e:
        return f"<h1>ç”Ÿæˆå‡ºé”™</h1><p>{e}</p>"

# ================= ä¸»ç¨‹åº =================
if __name__ == "__main__":
    raw_data = get_data()
    if not raw_data: raw_data = "No data."
    
    html_page = analyze_to_html(raw_data)
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_page)
    
    print("âœ… ä»»åŠ¡å®Œæˆ")
