import os
import feedparser
import google.generativeai as genai
from pytrends.request import TrendReq
from datetime import datetime

# ================= é…ç½®åŒº =================
api_key = os.environ.get("GOOGLE_API_KEY")

# ================= 1. è‡ªåŠ¨å¯»æ‰¾å¯ç”¨æ¨¡å‹ =================
def get_available_model():
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° API Key")
        return None
    
    genai.configure(api_key=api_key)
    
    print("ğŸ” æ­£åœ¨å¯»æ‰¾å¯ç”¨æ¨¡å‹...")
    try:
        # åˆ—å‡ºæ‰€æœ‰æ”¯æŒç”Ÿæˆçš„æ¨¡å‹
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"âœ… æ‰¾åˆ°å¯ç”¨æ¨¡å‹: {m.name}")
                return genai.GenerativeModel(m.name)
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾æ¨¡å‹å¤±è´¥: {e}")
        return None
    
    print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ API Key æƒé™")
    return None

# ================= 2. æŠ“å–æ•°æ® =================
def get_data():
    print("ğŸš€ å¼€å§‹é‡‡é›†æ•°æ®...")
    data_text = ""
    
    # Reddit
    try:
        print("æ­£åœ¨è¿æ¥ Reddit...")
        feed = feedparser.parse("https://www.reddit.com/r/popular/top/.rss?t=day", agent="Mozilla/5.0")
        if feed.entries:
            data_text += "ã€Reddit çƒ­é—¨è¯é¢˜ã€‘:\n"
            for entry in feed.entries[:7]:
                data_text += f"- {entry.title}\n"
    except Exception as e:
        print(f"âš ï¸ Reddit æŠ“å–è·³è¿‡: {e}")

    # Google Trends
    try:
        print("æ­£åœ¨è¿æ¥ Google Trends...")
        pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25))
        trends = pytrends.trending_searches(pn='united_states').head(10)[0].tolist()
        data_text += "\nã€Google æœç´¢çƒ­è¯ã€‘:\n"
        for t in trends:
            data_text += f"- {t}\n"
    except Exception as e:
        print(f"âš ï¸ Google Trends æŠ“å–è·³è¿‡: {e}")
            
    return data_text

# ================= 3. ç”Ÿæˆç½‘é¡µ =================
def analyze_to_html(text_data):
    # è·å–è‡ªé€‚åº”æ¨¡å‹
    model = get_available_model()
    if not model:
        return "<h1>AI é…ç½®å¤±è´¥</h1><p>æ— æ³•è¿æ¥ Google AIï¼Œè¯·æ£€æŸ¥ Logsã€‚</p>"

    date_str = datetime.now().strftime("%Y-%m-%d")
    print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆå†…å®¹...")
    
    prompt = f"""
    ä»Šå¤©æ˜¯ {date_str}ã€‚
    è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®å†™ä¸€ä¸ª HTML5 ç½‘é¡µã€‚
    
    è¦æ±‚ï¼š
    1. å¿…é¡»æ˜¯å®Œæ•´çš„ HTML ç»“æ„ï¼ŒåŒ…å« <head> å’Œ <body>ã€‚
    2. ä½¿ç”¨å†…åµŒ CSS ç¾åŒ–ï¼Œé£æ ¼ä¸ºâ€œæç®€æ–°é—»æ—¥æŠ¥â€ï¼ŒèƒŒæ™¯è‰² #f0f2f5ï¼Œå¡ç‰‡ç™½åº•åœ†è§’ï¼Œé˜´å½±æŸ”å’Œã€‚
    3. æ ‡é¢˜ï¼šğŸ‡ºğŸ‡¸ ç¾å›½å…¨ç½‘çƒ­ç‚¹æ—¥æŠ¥ ({date_str})ã€‚
    4. å†…å®¹ï¼šé€‰å‡º 5 ä¸ªæœ€çƒ­äº‹ä»¶ï¼Œæ¯ä¸ªäº‹ä»¶ä¸€ä¸ªå¡ç‰‡ã€‚
    5. ä¸è¦è¾“å‡º markdown ç¬¦å·ï¼Œåªè¾“å‡ºçº¯ HTML ä»£ç ã€‚
    
    æ•°æ®ï¼š
    {text_data}
    """

    try:
        response = model.generate_content(prompt)
        return response.text.replace("```html", "").replace("```", "")
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå‡ºé”™: {e}")
        return f"<h1>ç”Ÿæˆå‡ºé”™</h1><p>{e}</p>"

# ================= ä¸»ç¨‹åº =================
if __name__ == "__main__":
    raw_data = get_data()
    if not raw_data:
        raw_data = "æš‚æ— æ•°æ®ï¼Œå¯èƒ½æ˜¯ç½‘ç»œè¿æ¥é—®é¢˜ã€‚"
    
    html_page = analyze_to_html(raw_data)
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_page)
    
    print("âœ… ä»»åŠ¡å®Œæˆ")
